{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "# see the elements shape\n",
    "import h5py\n",
    "import tqdm\n",
    "import os\n",
    "count=0\n",
    "for index,i in enumerate(os.listdir(\"/media/jyxc/T5 EVO/yun_clothes-post/\")):\n",
    "    file_path=f\"/media/jyxc/T5 EVO/yun_clothes-post/{i}\"\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        print(file['action'].shape[0])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 66/66 [00:00<00:00, 783.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1/66: (195, 14)\n",
      "File 2/66: (200, 14)\n",
      "File 3/66: (200, 14)\n",
      "File 4/66: (200, 14)\n",
      "File 5/66: (200, 14)\n",
      "File 6/66: (200, 14)\n",
      "File 7/66: (200, 14)\n",
      "File 8/66: (200, 14)\n",
      "File 9/66: (151, 14)\n",
      "File 10/66: (200, 14)\n",
      "File 11/66: (156, 14)\n",
      "File 12/66: (180, 14)\n",
      "File 13/66: (177, 14)\n",
      "File 14/66: (200, 14)\n",
      "File 15/66: (143, 14)\n",
      "File 16/66: (200, 14)\n",
      "File 17/66: (200, 14)\n",
      "File 18/66: (200, 14)\n",
      "File 19/66: (178, 14)\n",
      "File 20/66: (200, 14)\n",
      "File 21/66: (142, 14)\n",
      "File 22/66: (176, 14)\n",
      "File 23/66: (189, 14)\n",
      "File 24/66: (200, 14)\n",
      "File 25/66: (200, 14)\n",
      "File 26/66: (200, 14)\n",
      "File 27/66: (167, 14)\n",
      "File 28/66: (175, 14)\n",
      "File 29/66: (200, 14)\n",
      "File 30/66: (157, 14)\n",
      "File 31/66: (200, 14)\n",
      "File 32/66: (113, 14)\n",
      "File 33/66: (200, 14)\n",
      "File 34/66: (192, 14)\n",
      "File 35/66: (127, 14)\n",
      "File 36/66: (137, 14)\n",
      "File 37/66: (196, 14)\n",
      "File 38/66: (200, 14)\n",
      "File 39/66: (200, 14)\n",
      "File 40/66: (200, 14)\n",
      "File 41/66: (142, 14)\n",
      "File 42/66: (200, 14)\n",
      "File 43/66: (142, 14)\n",
      "File 44/66: (107, 14)\n",
      "File 45/66: (200, 14)\n",
      "File 46/66: (168, 14)\n",
      "File 47/66: (181, 14)\n",
      "File 48/66: (200, 14)\n",
      "File 49/66: (123, 14)\n",
      "File 50/66: (153, 14)\n",
      "File 51/66: (200, 14)\n",
      "File 52/66: (156, 14)\n",
      "File 53/66: (200, 14)\n",
      "File 54/66: (139, 14)\n",
      "File 55/66: (200, 14)\n",
      "File 56/66: (200, 14)\n",
      "File 57/66: (200, 14)\n",
      "File 58/66: (175, 14)\n",
      "File 59/66: (200, 14)\n",
      "File 60/66: (200, 14)\n",
      "File 61/66: (200, 14)\n",
      "File 62/66: (121, 14)\n",
      "File 63/66: (162, 14)\n",
      "File 64/66: (172, 14)\n",
      "File 65/66: (200, 14)\n",
      "File 66/66: (200, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# add tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "count = 0\n",
    "file_list = os.listdir(\"/media/jyxc/T5 EVO/international_cheese/aloha_mobile_dummy/\")\n",
    "\n",
    "for index, i in tqdm(enumerate(file_list), total=len(file_list), desc=\"Processing files\"):\n",
    "    file_path = f\"/media/jyxc/T5 EVO/international_cheese/aloha_mobile_dummy/{i}\"\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        tqdm.write(f\"File {index + 1}/{len(file_list)}: {file['action'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_0.hdf5\n",
      "Data have less than 450!\n",
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_1.hdf5\n",
      "Data have less than 450!\n",
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_2.hdf5\n",
      "Data have less than 450!\n",
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_3.hdf5\n",
      "Creating HDF5 file: /media/jyxc/T5 EVO/yun_clothes-post/episode_0.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   4%|▍         | 4/101 [00:01<00:34,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_4.hdf5\n",
      "Data have less than 450!\n",
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_5.hdf5\n",
      "Data have less than 450!\n",
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_6.hdf5\n",
      "Data have less than 450!\n",
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_7.hdf5\n",
      "Creating HDF5 file: /media/jyxc/T5 EVO/yun_clothes-post/episode_1.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  10%|▉         | 10/101 [00:41<06:25,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_8.hdf5\n",
      "Data have less than 450!\n",
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_9.hdf5\n",
      "Data have less than 450!\n",
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_10.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  10%|▉         | 10/101 [00:55<06:25,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HDF5 file: /media/jyxc/T5 EVO/yun_clothes-post/episode_2.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  11%|█         | 11/101 [01:20<15:27, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: /media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/episode_11.hdf5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "count = 0\n",
    "file_list = os.listdir(\"/media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy\")\n",
    "\n",
    "# 使用 tqdm 创建总体进度条\n",
    "for index, i in tqdm(enumerate(file_list), total=len(file_list), desc=\"Processing files\"):\n",
    "    if i == 1:\n",
    "        break\n",
    "    file_path = f\"/media/jyxc/T5 EVO/yun_clothes/aloha_mobile_dummy/{i}\"\n",
    "    print(f\"\\nProcessing file: {file_path}\")\n",
    "\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            if file['action'].shape[0] < 450:\n",
    "                print(\"Data have less than 450!\")\n",
    "                continue\n",
    "            \n",
    "            is_sim = file.attrs['sim']\n",
    "            is_compress = file.attrs['compress']\n",
    "            \n",
    "            if 'action' in file:\n",
    "                base_action = file['base_action'][:][10:450,:]\n",
    "                cam_high = file['observations/images/cam_high'][:][10:450,:]\n",
    "                cam_right_wrist = file['observations/images/cam_right_wrist'][:][10:450,:]\n",
    "                cam_left_wrist = file['observations/images/cam_left_wrist'][:][10:450,:]\n",
    "                qpos = file['observations/qpos'][:][10:450,]\n",
    "                action = file['action'][:][10:450,]\n",
    "            else:\n",
    "                print(\"Data have no action!\")\n",
    "                continue  \n",
    "            \n",
    "            if action.shape[0] != 440:\n",
    "                continue\n",
    "\n",
    "        output_path = f\"/media/jyxc/T5 EVO/yun_clothes-post/episode_{count}.hdf5\"\n",
    "        print(f\"Creating HDF5 file: {output_path}\")\n",
    "\n",
    "        with h5py.File(output_path, 'w') as h5_file:\n",
    "            count += 1\n",
    "            obs_group = h5_file.create_group('observations')\n",
    "            h5_file.attrs['sim'] = is_sim\n",
    "            h5_file.attrs['compress'] = is_compress\n",
    "            img_group = obs_group.create_group('images')\n",
    "            \n",
    "            # 使用 tqdm 创建数据集写入进度条\n",
    "            with tqdm(total=6, desc=\"Writing datasets\", leave=False) as pbar:\n",
    "                h5_file.create_dataset('action', data=action)\n",
    "                pbar.update(1)\n",
    "                h5_file.create_dataset('base_action', data=base_action)\n",
    "                pbar.update(1)\n",
    "                img_group.create_dataset('cam_high', data=cam_high)\n",
    "                pbar.update(1)\n",
    "                img_group.create_dataset('cam_right_wrist', data=cam_right_wrist)\n",
    "                pbar.update(1)\n",
    "                img_group.create_dataset('cam_left_wrist', data=cam_left_wrist)\n",
    "                pbar.update(1)\n",
    "                obs_group.create_dataset('qpos', data=qpos)\n",
    "                pbar.update(1)\n",
    "\n",
    "        del action, base_action, cam_high, cam_left_wrist, cam_right_wrist, is_sim, is_compress\n",
    "\n",
    "    except OSError as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTotal processed files: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "count = 0\n",
    "file_list = os.listdir(\"/media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy\")\n",
    "\n",
    "# 使用 tqdm 创建总体进度条\n",
    "for index, i in tqdm(enumerate(file_list), total=len(file_list), desc=\"Processing files\"):\n",
    "    if i == 1:\n",
    "        break\n",
    "    file_path = f\"/media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/{i}\"\n",
    "    print(f\"\\nProcessing file: {file_path}\")\n",
    "\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            if file['action'].shape[0] < 1000:\n",
    "                print(\"Data have less than 1000!\")\n",
    "                continue\n",
    "            \n",
    "            is_sim = file.attrs['sim']\n",
    "            is_compress = file.attrs['compress']\n",
    "            \n",
    "            if 'action' in file:\n",
    "                base_action = file['base_action'][:][10:1000,:]\n",
    "                cam_high = file['observations/images/cam_high'][:][10:1000,:]\n",
    "                cam_right_wrist = file['observations/images/cam_right_wrist'][:][10:1000,:]\n",
    "                cam_left_wrist = file['observations/images/cam_left_wrist'][:][10:1000,:]\n",
    "                qpos = file['observations/qpos'][:][10:1000,]\n",
    "                action = file['action'][:][10:1000,]\n",
    "            else:\n",
    "                print(\"Data have no action!\")\n",
    "                continue  \n",
    "            \n",
    "            if action.shape[0] != 990:\n",
    "                continue\n",
    "\n",
    "        output_path = f\"/media/jyxc/T5 EVO/pick_3_pens-post/episode_{count}.hdf5\"\n",
    "        print(f\"Creating HDF5 file: {output_path}\")\n",
    "\n",
    "        with h5py.File(output_path, 'w') as h5_file:\n",
    "            count += 1\n",
    "            obs_group = h5_file.create_group('observations')\n",
    "            h5_file.attrs['sim'] = is_sim\n",
    "            h5_file.attrs['compress'] = is_compress\n",
    "            img_group = obs_group.create_group('images')\n",
    "            \n",
    "            # 使用 tqdm 创建数据集写入进度条\n",
    "            with tqdm(total=6, desc=\"Writing datasets\", leave=False) as pbar:\n",
    "                h5_file.create_dataset('action', data=action)\n",
    "                pbar.update(1)\n",
    "                h5_file.create_dataset('base_action', data=base_action)\n",
    "                pbar.update(1)\n",
    "                img_group.create_dataset('cam_high', data=cam_high)\n",
    "                pbar.update(1)\n",
    "                img_group.create_dataset('cam_right_wrist', data=cam_right_wrist)\n",
    "                pbar.update(1)\n",
    "                img_group.create_dataset('cam_left_wrist', data=cam_left_wrist)\n",
    "                pbar.update(1)\n",
    "                obs_group.create_dataset('qpos', data=qpos)\n",
    "                pbar.update(1)\n",
    "\n",
    "        del action, base_action, cam_high, cam_left_wrist, cam_right_wrist, is_sim, is_compress\n",
    "\n",
    "    except OSError as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTotal processed files: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data have less than 1000!\n",
      "Data have less than 1000!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   5%|▍         | 4/81 [15:41<4:32:55, 212.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_13.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_13.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n",
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_2.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_2.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   6%|▌         | 5/81 [16:27<3:22:50, 160.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_14.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_14.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   7%|▋         | 6/81 [18:02<2:54:43, 139.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_15.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_15.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   9%|▊         | 7/81 [18:49<2:17:12, 111.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_7.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_7.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  11%|█         | 9/81 [19:13<1:10:51, 59.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_16.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_16.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n",
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_6.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_6.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  12%|█▏        | 10/81 [19:59<1:05:00, 54.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_5.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_5.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  16%|█▌        | 13/81 [20:25<28:06, 24.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_3.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_3.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n",
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_9.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_9.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n",
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_10.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_10.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  17%|█▋        | 14/81 [21:34<40:07, 35.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_4.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_4.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  19%|█▊        | 15/81 [21:58<35:55, 32.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy/episode_8.hdf5: [Errno 2] Unable to synchronously create file (unable to open file: name = '/media/jyxc/T5 EVO/pick_3_pens-post/episode_8.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  19%|█▊        | 15/81 [25:14<1:51:03, 100.96s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def process_file(file_path, output_dir, file_count):\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            if file['action'].shape[0] < 1000:\n",
    "                return None, \"Data have less than 1000!\"\n",
    "            \n",
    "            is_sim = file.attrs['sim']\n",
    "            is_compress = file.attrs['compress']\n",
    "            \n",
    "            if 'action' not in file:\n",
    "                return None, \"Data have no action!\"\n",
    "            \n",
    "            base_action = file['base_action'][:][10:1000,:]\n",
    "            cam_high = file['observations/images/cam_high'][:][10:1000,:]\n",
    "            cam_right_wrist = file['observations/images/cam_right_wrist'][:][10:1000,:]\n",
    "            cam_left_wrist = file['observations/images/cam_left_wrist'][:][10:1000,:]\n",
    "            qpos = file['observations/qpos'][:][10:1000,]\n",
    "            action = file['action'][:][10:1000,]\n",
    "            \n",
    "            if action.shape[0] != 990:\n",
    "                return None, \"Action shape is not 990!\"\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"episode_{file_count}.hdf5\")\n",
    "        \n",
    "        with h5py.File(output_path, 'w') as h5_file:\n",
    "            obs_group = h5_file.create_group('observations')\n",
    "            h5_file.attrs['sim'] = is_sim\n",
    "            h5_file.attrs['compress'] = is_compress\n",
    "            img_group = obs_group.create_group('images')\n",
    "            \n",
    "            h5_file.create_dataset('action', data=action)\n",
    "            h5_file.create_dataset('base_action', data=base_action)\n",
    "            img_group.create_dataset('cam_high', data=cam_high)\n",
    "            img_group.create_dataset('cam_right_wrist', data=cam_right_wrist)\n",
    "            img_group.create_dataset('cam_left_wrist', data=cam_left_wrist)\n",
    "            obs_group.create_dataset('qpos', data=qpos)\n",
    "\n",
    "        return output_path, \"Success\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, f\"Error processing {file_path}: {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    input_dir = \"/media/jyxc/T5 EVO/pick_3_pens/aloha_mobile_dummy\"\n",
    "    output_dir = \"/media/jyxc/T5 EVO/pick_3_pens-post\"\n",
    "    file_list = os.listdir(input_dir)\n",
    "    \n",
    "    # 设置线程数，可以根据你的系统配置调整\n",
    "    max_workers = 16\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for i, filename in enumerate(file_list):\n",
    "            if filename == '1':\n",
    "                break\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            futures.append(executor.submit(process_file, file_path, output_dir, i))\n",
    "\n",
    "        successful_count = 0\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing files\"):\n",
    "            result, message = future.result()\n",
    "            if result:\n",
    "                successful_count += 1\n",
    "            else:\n",
    "                print(message)\n",
    "\n",
    "    print(f\"\\nTotal successfully processed files: {successful_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aloha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
